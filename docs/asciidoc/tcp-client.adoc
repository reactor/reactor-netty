:sourcedir: ./../../reactor-netty-core/src/main/java
:examplesdir: ./../../reactor-netty-examples/src/main/java/reactor/netty/examples/documentation/tcp/client
:javadoc: https://projectreactor.io/docs/netty/release/api

[[tcp-client]]
= TCP Client

Reactor Netty provides the easy-to-use and easy-to-configure
{javadoc}/reactor/netty/tcp/TcpClient.html[`TcpClient`].
It hides most of the Netty functionality that is needed in order to create a `TCP` client
and adds Reactive Streams backpressure.

== Connect and Disconnect

To connect the `TCP` client to a given endpoint, you must create and configure a
{javadoc}/reactor/netty/tcp/TcpClient.html[`TcpClient`] instance.
By default, the `host` is `localhost` and the `port` is `12012`.
The following example shows how to create a `TcpClient`:

====
[source,java,indent=0]
.{examplesdir}/create/Application.java
----
include::{examplesdir}/create/Application.java[lines=18..31]
----
<1> Creates a {javadoc}/reactor/netty/tcp/TcpClient.html[`TcpClient`]
instance that is ready for configuring.
<2> Connects the client in a blocking fashion and waits for it to finish initializing.
====

The returned {javadoc}/reactor/netty/Connection.html[`Connection`]
offers a simple connection API, including {javadoc}/reactor/netty/DisposableChannel.html#disposeNow-java.time.Duration-[`disposeNow()`],
which shuts the client down in a blocking fashion.

=== Host and Port

To connect to a specific `host` and `port`, you can apply the following configuration to the `TCP` client.
The following example shows how to do so:

====
[source,java,indent=0]
.{examplesdir}/address/Application.java
----
include::{examplesdir}/address/Application.java[lines=18..33]
----
<1> Configures the `TCP` host
<2> Configures the `TCP` port
====

== Writing Data

To send data to a given endpoint, you must attach an I/O handler.
The I/O handler has access to {javadoc}/reactor/netty/NettyOutbound.html[`NettyOutbound`]
to be able to write data.

====
[source,java,indent=0]
.{examplesdir}/send/Application.java
----
include::{examplesdir}/send/Application.java[lines=18..35]
----
<1> Sends `hello` string to the endpoint.
====

== Consuming Data

To receive data from a given endpoint, you must attach an I/O handler.
The I/O handler has access to {javadoc}/reactor/netty/NettyInbound.html[`NettyInbound`]
to be able to read data. The following example shows how to do so:

====
[source,java,indent=0]
.{examplesdir}/read/Application.java
----
include::{examplesdir}/read/Application.java[lines=18..34]
----
<1> Receives data from a given endpoint
====

== Lifecycle Callbacks

The following lifecycle callbacks are provided to let you extend the `TCP` client.

* `doOnConnect`: Invoked when the channel is about to connect.
* `doOnConnected`: Invoked after the channel has been connected.
* `doOnDisconnected`: Invoked after the channel has been disconnected.

The following example uses the `doOnConnected` callback:

====
[source,java,indent=0]
.{examplesdir}/lifecycle/Application.java
----
include::{examplesdir}/lifecycle/Application.java[lines=18..37]
----
<1> `Netty` pipeline is extended with `ReadTimeoutHandler` when the channel has been connected.
====

== TCP-level Configurations

This section describes three kinds of configuration that you can use at the TCP level:

* <<client-tcp-level-configurations-channel-options>>
* <<client-tcp-level-configurations-event-wire-logger>>
* <<client-tcp-level-configurations-event-loop-group>>

[[client-tcp-level-configurations-channel-options]]
=== Channel Options

By default, the `TCP` client is configured with the following options:

====
[source,java,indent=0]
.{sourcedir}/reactor/netty/tcp/TcpClientConnect.java
----
include::{sourcedir}/reactor/netty/tcp/TcpClientConnect.java[lines=38..43]
----
====

If additional options are necessary or changes to the current options are needed, you can apply the following configuration:

====
[source,java,indent=0]
.{examplesdir}/channeloptions/Application.java
----
include::{examplesdir}/channeloptions/Application.java[lines=18..35]
----
====

You can find more about `Netty` channel options at the following links:

* https://netty.io/4.1/api/io/netty/channel/ChannelOption.html[`ChannelOption`]
* https://docs.oracle.com/javase/8/docs/technotes/guides/net/socketOpt.html[Socket Options]

[[client-tcp-level-configurations-event-wire-logger]]
=== Wire Logger

Reactor Netty provides wire logging for when the traffic between the peers has to be inspected.
By default, wire logging is disabled.
To enable it, you must set the logger `reactor.netty.tcp.TcpClient` level to `DEBUG`
and apply the following configuration:

====
[source,java,indent=0]
.{examplesdir}/wiretap/Application.java
----
include::{examplesdir}/wiretap/Application.java[lines=18..34]
----
<1> Enables the wire logging
====

[[client-tcp-level-configurations-event-loop-group]]
=== Event Loop Group

By default the `TCP` client uses an "`Event Loop Group`", where the number of the worker threads equals the number of
processors available to the runtime on initialization (but with a minimum value of 4). When you need a different configuration,
you can use one of the {javadoc}/reactor/netty/resources/LoopResources.html[LoopResource]`#create`
methods.

The following listing shows the default configuration for the Event Loop Group:

====
[source,java,indent=0]
.{sourcedir}/reactor/netty/ReactorNetty.java
----
include::{sourcedir}/reactor/netty/ReactorNetty.java[lines=78..107]
----
====

If you need changes to the these settings, you can apply the following configuration:

====
[source,java,indent=0]
.{examplesdir}/eventloop/Application.java
----
include::{examplesdir}/eventloop/Application.java[lines=18..37]
----
====

== Connection Pool

By default, the `TCP` client uses a "`fixed`" connection pool with `500` as the maximum number of channels
and `1000` as the maximum number of the registered requests for acquire to keep in the pending queue
(for the rest of the configurations check the system properties below).
This means that the implementation creates a new channel if someone tries to acquire a channel but none is in the pool.
When the maximum number of the channels in the pool is reached, new tries to acquire a channel are delayed
until a channel is returned to the pool again.

====
[source,java,indent=0]
.{sourcedir}/reactor/netty/ReactorNetty.java
----
include::{sourcedir}/reactor/netty/ReactorNetty.java[lines=114..135]
----
====


If you need to disable the connection pool, you can apply the following configuration:

====
[source,java,indent=0]
.{examplesdir}/pool/Application.java
----
include::{examplesdir}/pool/Application.java[lines=18..33]
----
====

If you need to specify an idle time for the channels in the connection pool, you can apply the following configuration:

====
[source,java,indent=0]
.{examplesdir}/pool/config/Application.java
----
include::{examplesdir}/pool/config/Application.java[lines=18..42]
----
====

NOTE: When you expect a high load, be cautious with a connection pool with a very high value for maximum connections. You might experience
`reactor.netty.http.client.PrematureCloseException` exception with a root cause "Connect Timeout" due
to too many concurrent connections opened/acquired.

=== Metrics
The pooled `ConnectionProvider` supports built-in integration with https://micrometer.io/[`Micrometer`].
It exposes all metrics with a prefix of `reactor.netty.connection.provider`.

include::conn-provider-metrics.adoc[]

The following example enables that integration:

====
[source,java,indent=0]
.{examplesdir}/pool/metrics/Application.java
----
include::{examplesdir}/pool/metrics/Application.java[lines=18..40]
----
<1> Enables the built-in integration with Micrometer
====

== SSL and TLS

When you need SSL or TLS, you can apply the following configuration.
By default, if `OpenSSL` is available, the
https://netty.io/4.1/api/io/netty/handler/ssl/SslProvider.html#OPENSSL[`SslProvider.OPENSSL`]
provider is used as a provider. Otherwise, the provider is
https://netty.io/4.1/api/io/netty/handler/ssl/SslProvider.html#JDK[`SslProvider.JDK`].
You can switch the provider by using
https://netty.io/4.1/api/io/netty/handler/ssl/SslContextBuilder.html#sslProvider-io.netty.handler.ssl.SslProvider-[`SslContextBuilder`]
or by setting `-Dio.netty.handler.ssl.noOpenSsl=true`.

The following example uses `SslContextBuilder`:

====
[source,java,indent=0]
.{examplesdir}/security/Application.java
----
include::{examplesdir}/security/Application.java[lines=18..37]
----
====

=== Server Name Indication
By default, the `TCP` client sends the remote host name as `SNI` server name.
When you need to change this default setting, you can configure the `TCP` client as follows:

====
[source,java,indent=0]
.{examplesdir}/sni/Application.java
----
include::{examplesdir}/sni/Application.java[lines=18..41]
----
====

== Proxy Support

The TCP client supports the proxy functionality provided by Netty and provides a way
to specify "`non proxy hosts`" through the {javadoc}/reactor/netty/tcp/ProxyProvider.html[`ProxyProvider`] builder.
The following example uses `ProxyProvider`:

====
[source,java,indent=0]
.{examplesdir}/proxy/Application.java
----
include::{examplesdir}/proxy/Application.java[lines=18..38]
----
====

== Metrics
The TCP client supports built-in integration with https://micrometer.io/[`Micrometer`].
It exposes all metrics with a prefix of `reactor.netty.tcp.client`.

The following table provides information for the TCP client metrics:

[width="100%",options="header"]
|=======
| metric name | type | description
| reactor.netty.tcp.client.data.received | DistributionSummary | Amount of the data received, in bytes
| reactor.netty.tcp.client.data.sent | DistributionSummary | Amount of the data sent, in bytes
| reactor.netty.tcp.client.errors | Counter | Number of errors that occurred
| reactor.netty.tcp.client.tls.handshake.time | Timer | Time spent for TLS handshake
| reactor.netty.tcp.client.connect.time | Timer | Time spent for connecting to the remote address
| reactor.netty.tcp.client.address.resolver | Timer | Time spent for resolving the address
|=======

These additional metrics are also available:

include::conn-provider-metrics.adoc[]

include::alloc-metrics.adoc[]

The following example enables that integration:

====
[source,java,indent=0]
.{examplesdir}/metrics/Application.java
----
include::{examplesdir}/metrics/Application.java[lines=18..34]
----
<1> Enables the built-in integration with Micrometer
====

When TCP client metrics are needed for an integration with a system other than `Micrometer` or you want
to provide your own integration with `Micrometer`, you can provide your own metrics recorder, as follows:

====
[source,java,indent=0]
.{examplesdir}/metrics/custom/Application.java
----
include::{examplesdir}/metrics/custom/Application.java[lines=18..37]
----
<1> Enables TCP client metrics and provides {javadoc}/reactor/netty/channel/ChannelMetricsRecorder.html[`ChannelMetricsRecorder`] implementation.
====

== Unix Domain Sockets
The `TCP` client supports Unix Domain Sockets (UDS) when native transport is in use.

The following example shows how to use UDS support:

====
[source,java,indent=0]
.{examplesdir}/uds/Application.java
----
include::{examplesdir}/uds/Application.java[lines=18..33]
----
<1> Specifies `DomainSocketAddress` that will be used
====
